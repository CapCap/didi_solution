{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "#import tensorflow as tf\n",
    "import glob\n",
    "import pcl\n",
    "import math\n",
    "import pickle\n",
    "import six\n",
    "import parse_xml as pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "def pv(var):\n",
    "    (filename,line_number,function_name,text)=traceback.extract_stack()[-2]\n",
    "    print('%s: %s'%(text[text.find('(')+1:-1],var))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import model_01_conv\n",
    "import layers\n",
    "import input_helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload everything\n",
    "\n",
    "import imp \n",
    "\n",
    "imp.reload(input_helpers)\n",
    "imp.reload(layers)\n",
    "imp.reload(model_01_conv)\n",
    "layers.cnn_model = None\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clear graph\n",
    "try:\n",
    "    with model_01_conv.tf.Session() as sess:\n",
    "        #with model_01_conv.tf.device(\"/cpu:0\"):\n",
    "        model_01_conv.tf.reset_default_graph()\n",
    "    None\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resolution=0.1,\n",
    "scale=8,\n",
    "voxel_shape=(800, 800, 80),\n",
    "x=(-40, 40),\n",
    "y=(-40, 40),\n",
    "z=(-4, 4),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n"
     ]
    }
   ],
   "source": [
    "model_name = \"3dcnn_800x800x80_res0.1_sc86.ckpt\"\n",
    "model_path = \"/home/paperspace/Desktop/didi_solution/cnn_3d/\"+model_name\n",
    "\n",
    "model = model_01_conv.CNNModel(resolution=0.1,\n",
    "                                scale=8,\n",
    "                                voxel_shape=(800, 800, 80),\n",
    "                                x=(-40, 40),\n",
    "                                y=(-40, 40),\n",
    "                                z=(-4, 4),\n",
    "                                is_training=None,\n",
    "                                model_path=model_path\n",
    "                               )\n",
    "\n",
    "model.build_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: '/home/paperspace/Desktop/converted/car/testing/ford03/points/*'\n",
      "saving to: '/home/paperspace/Desktop/didi_solution/cnn_3d/test_output/ford03/results.pickle'\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import conversion_helpers\n",
    "from collections import defaultdict\n",
    "\n",
    "def make_frame_result_dict_shell():\n",
    "    return {'pred': {}, 'actual': {}}\n",
    "\n",
    "test_folder_glob = \"/home/paperspace/Desktop/converted/car/testing/*\"\n",
    "\n",
    "\n",
    "for test_folder in glob.glob(test_folder_glob):\n",
    "    bag_name = test_folder.split('/')[-1]\n",
    "    if bag_name != \"ford03\":\n",
    "        continue\n",
    "    output_dir = os.path.join(os.getcwd(), 'test_output', bag_name)\n",
    "    conversion_helpers.mkdir_p(output_dir)\n",
    "    pcd_glob = os.path.join(test_folder, 'points', '*')\n",
    "    \n",
    "    print(\"processing: '%s'\"%pcd_glob)\n",
    "    results = defaultdict(make_frame_result_dict_shell)\n",
    "    \n",
    "    for point_path in glob.glob(pcd_glob):\n",
    "        frame_id = point_path.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        pc = input_helpers.load_pc_from_pcd(point_path)\n",
    "        \n",
    "        corners, centers, rotations, confidence = model.predict(pc)\n",
    "        results[frame_id]['pred'] = {\n",
    "            'corners': corners,\n",
    "            'centers': centers,\n",
    "            'confidence': confidence,\n",
    "            'rot': rotations\n",
    "        }\n",
    "\n",
    "    pickle_path = os.path.join(output_dir, \"results.pickle\")\n",
    "    print(\"saving to: '%s'\"%pickle_path) \n",
    "    pickle.dump(dict(results), open(pickle_path, \"wb\") )\n",
    "    \n",
    "    print(\" \")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracklets.python.generate_tracklet import Tracklet, TrackletCollection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_orientation(corners_initial):\n",
    "    corners_initial = np.reshape(corners_initial, (-1, 3))\n",
    "    average = np.sum(corners_initial, axis=0) / corners_initial.shape[0]\n",
    "    corners = corners_initial - average\n",
    "    convx_hull = np.reshape(cv2.convexHull(np.array(corners[:, :2], dtype=np.float32)), (-1, 2))\n",
    "    rotated_convx_hull = np.vstack((convx_hull[1:], convx_hull[:1]))\n",
    "    distance_delta = convx_hull - rotated_convx_hull\n",
    "    distance_delta = np.linalg.norm(convx_hull - rotated_convx_hull, axis=1)\n",
    "    length_of_car_from_convex_hull = np.max(distance_delta)\n",
    "    width_of_car_from_convex_hull = np.min(distance_delta)\n",
    "    l, w = length_of_car_from_convex_hull, width_of_car_from_convex_hull\n",
    "    a_mat = [[-l / 2., -w / 2.],\n",
    "            [l / 2., -w / 2.],\n",
    "            [-l / 2., w / 2.],\n",
    "            [-l / 2., -w / 2.],\n",
    "            [-l / 2., w / 2.],\n",
    "            [l / 2., w / 2.],\n",
    "            [l / 2., -w / 2.],\n",
    "            [l / 2., w / 2.]]\n",
    "    b_mat = corners[:, :2]\n",
    "    rot_mat = np.linalg.lstsq(a_mat, b_mat)[0]\n",
    "    angle = math.acos(rot_mat[0][0])\n",
    "    h = np.max(corners_initial[:, 2]) - np.min(corners_initial[:, 2])\n",
    "    return angle, l, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: '/home/paperspace/Desktop/didi_solution/cnn_3d/test_output/ford03/results.pickle'\n",
      "processing: '/home/paperspace/Desktop/didi_solution/cnn_3d/test_output/mustang01/results.pickle'\n",
      "processing: '/home/paperspace/Desktop/didi_solution/cnn_3d/test_output/ford07/results.pickle'\n",
      "processing: '/home/paperspace/Desktop/didi_solution/cnn_3d/test_output/ford05/results.pickle'\n",
      "processing: '/home/paperspace/Desktop/didi_solution/cnn_3d/test_output/ford06/results.pickle'\n",
      "processing: '/home/paperspace/Desktop/didi_solution/cnn_3d/test_output/ford04/results.pickle'\n",
      "processing: '/home/paperspace/Desktop/didi_solution/cnn_3d/test_output/ford02/results.pickle'\n",
      "processing: '/home/paperspace/Desktop/didi_solution/cnn_3d/test_output/ford01/results.pickle'\n"
     ]
    }
   ],
   "source": [
    "results_folder_glob = \"/home/paperspace/Desktop/didi_solution/cnn_3d/test_output/*\"\n",
    "xml_output_path = \"/home/paperspace/Desktop/didi_solution/cnn_3d/tracklet_output/\"\n",
    "\n",
    "for results_folder in glob.glob(results_folder_glob):\n",
    "    bag_name = results_folder.split('/')[-1]\n",
    "    results_pickle_path = os.path.join(results_folder, \"results.pickle\")\n",
    "    print(\"processing: '%s'\"%results_pickle_path)\n",
    "    \n",
    "    tc = TrackletCollection()\n",
    "    results = pickle.load(open(results_pickle_path, \"rb\") )\n",
    "    frame_ids = sorted(list(map(int, results.keys())))\n",
    "    \n",
    "    #if \"mustang\" in bag_name:\n",
    "    h = 1.481\n",
    "    w = 1.916\n",
    "    l = 4.785\n",
    "        \n",
    "    #else:\n",
    "    #    h = 1.6510\n",
    "    #    w = 1.7780\n",
    "    #    l = 4.5212\n",
    "\n",
    "    poses = []\n",
    "    last_pose = None\n",
    "    all_corners = []\n",
    "    starting_frame = 0\n",
    "    for frame_id in range(max(frame_ids)):\n",
    "        frame_results = results.get(str(frame_id), None)\n",
    "\n",
    "        frame_valid = False\n",
    "        \n",
    "        if frame_results:\n",
    "            pred = frame_results['pred']\n",
    "            \n",
    "            if pred['confidence'] is not None and pred['confidence'].shape[0] > 0:\n",
    "                frame_valid = True\n",
    "                res_i = np.argmax(pred['confidence'])\n",
    "\n",
    "                center = pred['centers'][res_i]\n",
    "                rot = pred['rot'][res_i]\n",
    "                corners = pred['corners'][res_i]\n",
    "                    \n",
    "                last_pose = {\n",
    "                    \"tx\": center[0],\n",
    "                    \"ty\": center[1],\n",
    "                    \"tz\": center[2],\n",
    "                    \"rx\": 0.0,\n",
    "                    \"ry\": 0.0,\n",
    "                    \"rz\": rot\n",
    "                }\n",
    "\n",
    "                poses.append(last_pose)\n",
    "\n",
    "            else:\n",
    "                frame_valid = False\n",
    "            \n",
    "        if not frame_valid:\n",
    "            if last_pose is None:\n",
    "                starting_frame += 1\n",
    "            else:\n",
    "                if starting_frame > 0:\n",
    "                    for i in range(starting_frame):\n",
    "                        poses.append(last_pose)\n",
    "                        starting_frame = 0\n",
    "                else:\n",
    "                    poses.append(last_pose)\n",
    "\n",
    "    tracklet = Tracklet(object_type=\"Car\", l=l, w=w, h=h)\n",
    "    for pose in poses:\n",
    "        tracklet.poses.append(pose)\n",
    "    tracklet.first_frame = 0\n",
    "    \n",
    "    tc.tracklets.append(tracklet)\n",
    "    tc.write_xml(os.path.join(xml_output_path, bag_name+\".xml\"))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#path_prefix = \"/home/paperspace/Desktop/converted/car/training/suburu_leading_front_left/*/\"\n",
    "#path_prefix = \"/home/paperspace/Desktop/converted/pedestrian/5/\"\n",
    "path_prefix = \"/home/paperspace/Desktop/converted/car/testing/ford04/\"\n",
    "points_glob = path_prefix+\"points/*.pcd\"\n",
    "\n",
    "points_paths = glob.glob(points_glob)\n",
    "points_path = points_paths[30]\n",
    "model.build_graph()\n",
    "\n",
    "folder_path = \"/home/paperspace/Desktop/converted/car/testing/*\"\n",
    "pc = input_helpers.load_pc_from_pcd(points_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took: 0.02688827117284139m\n",
      "took: 0.02916560967763265m\n",
      "took: 0.029087960720062256m\n",
      "took: 0.02827640771865845m\n",
      "took: 0.029466478029886882m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i in range(5):\n",
    "    t_start = time.time()\n",
    "    corners, centers, rotations, confidence = model.predict(pc)\n",
    "    print(\"took: %sm\"%str((time.time() - t_start)/60.0))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "#import tensorflow as tf\n",
    "import glob\n",
    "import pcl\n",
    "import math\n",
    "import pickle\n",
    "import six\n",
    "import parse_xml as pt\n",
    "import model_01_conv\n",
    "import layers\n",
    "import input_helpers\n",
    "import traceback\n",
    "def pv(var):\n",
    "    (filename,line_number,function_name,text)=traceback.extract_stack()[-2]\n",
    "    print('%s: %s'%(text[text.find('(')+1:-1],var))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def bring_bbox_to_ground(corners):\n",
    "    grounded_corners = []\n",
    "    for corner in corners.reshape(-1, 8, 3):\n",
    "        corner[:, 2] -= np.max(corner[:, 2])\n",
    "        grounded_corners.append(corner)\n",
    "    return np.array(grounded_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sensor_msgs.point_cloud2 as pc2\n",
    "import rospy\n",
    "from sensor_msgs.msg import PointCloud2\n",
    "import std_msgs\n",
    "from visualization_msgs.msg import Marker\n",
    "from geometry_msgs.msg import Point, TransformStamped\n",
    "import rospy\n",
    "\n",
    "node = rospy.init_node(\"pc2_publisher\")\n",
    "pub = rospy.Publisher(\"/points_raw\", PointCloud2, queue_size=1000000)\n",
    "pub2 = rospy.Publisher(\"/points_raw1\", PointCloud2, queue_size=1000000)\n",
    "pub3 = rospy.Publisher(\"/points_raw2\", PointCloud2, queue_size=1000000)\n",
    "\n",
    "model_name = \"3dcnn_800x800x80_res0.1_sc86.ckpt\"\n",
    "model_path = \"/home/paperspace/Desktop/didi_solution/cnn_3d/\"+model_name\n",
    "min_certainty = 0.90\n",
    "\n",
    "resolution=0.1\n",
    "scale=8\n",
    "voxel_shape=(800, 800, 80)\n",
    "x=(-40, 40)\n",
    "y=(-40, 40)\n",
    "z=(-4, 4)\n",
    "\n",
    "model = None\n",
    "voxel = None\n",
    "graph = None\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "def init_model():\n",
    "    global voxel\n",
    "    global model\n",
    "    global graph\n",
    "    if model is not None:\n",
    "        return model, voxel\n",
    "\n",
    "    with sess.as_default():\n",
    "        model, voxel, phase_train = model_01_conv.get_model(sess,\n",
    "                                                              model_01_conv.CNNModel,\n",
    "                                                              voxel_shape=voxel_shape,\n",
    "                                                              activation=tf.nn.relu,\n",
    "                                                              is_training=None)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, model_path)\n",
    "        graph = tf.get_default_graph()\n",
    "        \n",
    "        \n",
    "    return model, voxel\n",
    "\n",
    "init_model()\n",
    "\n",
    "\n",
    "def ros_subscriber():\n",
    "    #rospy.init_node(\"lidar2image\")\n",
    "    rospy.Subscriber(\"/velodyne_points\", PointCloud2, callback_got_lidar)\n",
    "    #pub = rospy.Publisher(\"/points_raw\", PointCloud2, queue_size=10)\n",
    "    \n",
    "    \n",
    "def callback_got_lidar(point_cloud):\n",
    "    global graph \n",
    "    \n",
    "    model, voxel = init_model()\n",
    "    pc = np.array([[point[0], point[1], point[2]] for point in pc2.read_points(point_cloud)])\n",
    "    #pv(pc.shape)\n",
    "    resolution=0.1\n",
    "    scale=8\n",
    "    voxel_shape=(800, 800, 80)\n",
    "    x=(-40, 40)\n",
    "    y=(-40, 40)\n",
    "    z=(-4, 4)\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    z = np.array(z)\n",
    "\n",
    "    voxel_pt = input_helpers.pc2voxel(pc,\n",
    "                             resolution=resolution,\n",
    "                             x=x,\n",
    "                             y=y,\n",
    "                             z=z)\n",
    "\n",
    "    voxel_x = np.array(voxel_pt).reshape(1, voxel_pt.shape[0], voxel_pt.shape[1], voxel_pt.shape[2], 1)\n",
    "    #pv(voxel_x.shape)\n",
    "    with graph.as_default():\n",
    "        with sess.as_default():\n",
    "            objectness = sess.run(model.objectness, feed_dict={voxel: voxel_x})[0, :, :, :, 0]\n",
    "            coordinate = sess.run(model.coordinate, feed_dict={voxel: voxel_x})[0]\n",
    "            y_pred = sess.run(model.y, feed_dict={voxel: voxel_x})[0, :, :, :, 0]\n",
    "\n",
    "            index = np.where(y_pred >= np.max(y_pred))# >= min_certainty)\n",
    "            index = np.array(index)\n",
    "\n",
    "            centers = np.vstack((index[0], np.vstack((index[1], index[2])))).transpose()\n",
    "            centers = input_helpers.sphere2center(centers,\n",
    "                                                resolution=resolution,\n",
    "                                                scale=scale,\n",
    "                                                min_value=np.array([x[0], y[0], z[0]]))\n",
    "\n",
    "            corners = coordinate[index[0], index[1], index[2]].reshape(-1, 8, 3)\n",
    "            corners = np.array([corners[t,:,:] + centers[t,:] for t in range(corners.shape[0])])\n",
    "            corners = bring_bbox_to_ground(corners)\n",
    "            rot = get_orientation(corners)\n",
    "            pv(rot)\n",
    "\n",
    "            ts = rospy.Time.now()\n",
    "            header = std_msgs.msg.Header()\n",
    "            header.stamp = ts\n",
    "            header.frame_id = \"velodyne\"\n",
    "            points = pc2.create_cloud_xyz32(header, corners.reshape(-1, 3))\n",
    "            pub2.publish(points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "points_path = \"/home/paperspace/Desktop/converted/car/testing/ford01/points/102.pcd\"\n",
    "pc = input_helpers.load_pc_from_pcd(points_path)\n",
    "ts = rospy.Time.now()\n",
    "header = std_msgs.msg.Header()\n",
    "header.stamp = ts\n",
    "header.frame_id = \"velodyne\"\n",
    "pz = pc2.create_cloud_xyz32(header, pc)\n",
    "callback_got_lidar(pz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ros_subscriber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_i_to_corners(corners):\n",
    "    i_corners = []\n",
    "    i=0\n",
    "\n",
    "    for corner in corners.reshape(-1, 8, 3):\n",
    "        new_corner = []\n",
    "        for c in corner:\n",
    "            new_corner.append([c[0], c[1], c[2], i])\n",
    "        i+=1\n",
    "        \n",
    "        i_corners.append(new_corner)\n",
    "    return np.array(i_corners)\n",
    "\n",
    "def bring_bbox_to_ground(corners):\n",
    "    grounded_corners = []\n",
    "    for corner in corners.reshape(-1, 8, 3):\n",
    "        corner[:, 2] -= np.max(corner[:, 2])\n",
    "        grounded_corners.append(corner)\n",
    "    return np.array(grounded_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def make_frame_result_dict_shell():\n",
    "    return {'pred': {}, 'actual': {}}\n",
    "results = defaultdict(make_frame_result_dict_shell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_id: 32\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  -0.258145 -229.481\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.364934 0.0\n",
      "centers:  []\n",
      "centers.shape:  (0, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.36493438]\n",
      "frame_id: 138\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  5.80532 -305.785\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.99999 0.0\n",
      "centers:  [[65 53  4]\n",
      " [65 53  5]\n",
      " [66 53  3]\n",
      " [66 53  4]\n",
      " [66 53  5]\n",
      " [67 53  4]]\n",
      "centers.shape:  (6, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.99999046]\n",
      "frame_id: 111\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  4.05557 -113.994\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.999683 0.0\n",
      "centers:  [[74 54  4]\n",
      " [75 54  4]\n",
      " [75 54  5]\n",
      " [75 55  4]\n",
      " [86 44  5]\n",
      " [86 45  4]\n",
      " [86 45  5]\n",
      " [86 46  4]\n",
      " [86 46  5]]\n",
      "centers.shape:  (9, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.99968278]\n",
      "frame_id: 51\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  -0.0148005 -239.324\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.48153 0.0\n",
      "centers:  []\n",
      "centers.shape:  (0, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.48153016]\n",
      "frame_id: 90\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  1.50231 -360.733\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.939017 0.0\n",
      "centers:  []\n",
      "centers.shape:  (0, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.93901682]\n",
      "frame_id: 205\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  2.7354 -333.976\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.995499 0.0\n",
      "centers:  [[81 44  4]\n",
      " [81 45  4]\n",
      " [87 44  3]]\n",
      "centers.shape:  (3, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.99549931]\n",
      "frame_id: 210\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  1.39922 -365.815\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.939865 0.0\n",
      "centers:  []\n",
      "centers.shape:  (0, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.9398647]\n",
      "frame_id: 231\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  1.14379 -334.02\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.892109 0.0\n",
      "centers:  []\n",
      "centers.shape:  (0, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.89210862]\n",
      "frame_id: 174\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  5.94023 -357.916\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.999993 0.0\n",
      "centers:  [[54 53  4]\n",
      " [54 53  5]\n",
      " [55 53  4]\n",
      " [55 53  5]\n",
      " [76 43  4]\n",
      " [88 47  5]]\n",
      "centers.shape:  (6, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.99999285]\n",
      "frame_id: 186\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  3.85847 -306.692\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.999515 0.0\n",
      "centers:  [[52 53  4]\n",
      " [53 53  4]\n",
      " [54 53  4]\n",
      " [60 44  4]\n",
      " [86 44  4]\n",
      " [86 44  5]\n",
      " [86 45  4]\n",
      " [86 45  5]\n",
      " [87 45  4]]\n",
      "centers.shape:  (9, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.9995153]\n",
      "frame_id: 37\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  1.7276 -280.865\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.966955 0.0\n",
      "centers:  [[85  7  4]]\n",
      "centers.shape:  (1, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.9669553]\n",
      "frame_id: 49\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  0.724132 -327.895\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.789787 0.0\n",
      "centers:  []\n",
      "centers.shape:  (0, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.78978735]\n",
      "frame_id: 13\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  -0.153944 -315.924\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.41717 0.0\n",
      "centers:  []\n",
      "centers.shape:  (0, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.41717023]\n",
      "frame_id: 147\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  4.75005 -298.943\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.999923 0.0\n",
      "centers:  [[62 53  4]\n",
      " [62 53  5]\n",
      " [63 53  4]\n",
      " [63 53  5]\n",
      " [64 53  4]]\n",
      "centers.shape:  (5, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.99992299]\n",
      "frame_id: 181\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  4.60441 -211.202\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.999897 0.0\n",
      "centers:  [[52 53  4]\n",
      " [53 53  4]\n",
      " [53 53  5]\n",
      " [54 53  4]\n",
      " [87 44  4]]\n",
      "centers.shape:  (5, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.99989665]\n",
      "frame_id: 135\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  4.15411 -283.796\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.999736 0.0\n",
      "centers:  [[66 53  4]\n",
      " [67 53  4]\n",
      " [68 53  4]\n",
      " [68 53  5]\n",
      " [68 54  4]\n",
      " [78 45  4]\n",
      " [88 44  4]]\n",
      "centers.shape:  (7, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.99973589]\n",
      "frame_id: 128\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  5.42884 -260.425\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.99998 0.0\n",
      "centers:  [[68 53  4]\n",
      " [69 53  4]\n",
      " [69 54  4]\n",
      " [70 53  4]\n",
      " [81 43  4]\n",
      " [81 43  5]\n",
      " [81 44  4]\n",
      " [81 44  5]\n",
      " [90 44  4]]\n",
      "centers.shape:  (9, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.99998009]\n",
      "frame_id: 251\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  3.23064 -333.207\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.998274 0.0\n",
      "centers:  [[34 54  4]\n",
      " [34 54  5]\n",
      " [41 44  4]\n",
      " [57 42  4]\n",
      " [57 42  5]\n",
      " [58 42  4]]\n",
      "centers.shape:  (6, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.99827373]\n",
      "frame_id: 68\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  0.714105 -328.53\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.786053 0.0\n",
      "centers:  []\n",
      "centers.shape:  (0, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.78605348]\n",
      "frame_id: 106\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  15.4841 -332.942\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  1.0 0.0\n",
      "centers:  [[51 38  4]\n",
      " [75 54  4]\n",
      " [76 54  4]\n",
      " [76 54  5]\n",
      " [76 55  4]\n",
      " [76 55  5]\n",
      " [77 54  4]\n",
      " [86 46  4]\n",
      " [86 46  5]]\n",
      "centers.shape:  (9, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 1.]\n",
      "frame_id: 241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  4.12826 -338.065\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.999722 0.0\n",
      "centers:  [[35 53  4]\n",
      " [36 53  4]\n",
      " [36 53  5]\n",
      " [37 53  4]]\n",
      "centers.shape:  (4, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.99972242]\n",
      "frame_id: 246\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  3.2232 -343.163\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.998258 0.0\n",
      "centers:  [[35 53  4]\n",
      " [35 53  5]]\n",
      "centers.shape:  (2, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.99825782]\n",
      "frame_id: 229\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  1.65574 -344.671\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.964245 0.0\n",
      "centers:  [[73 43  4]\n",
      " [73 44  4]]\n",
      "centers.shape:  (2, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.96424514]\n",
      "frame_id: 20\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  1.01661 -314.754\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.882208 0.0\n",
      "centers:  []\n",
      "centers.shape:  (0, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.88220793]\n",
      "frame_id: 203\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  2.77412 -306.324\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.995611 0.0\n",
      "centers:  [[55 44  4]\n",
      " [56 44  4]\n",
      " [82 44  5]]\n",
      "centers.shape:  (3, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.99561089]\n",
      "frame_id: 140\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  5.14027 -299.734\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.999964 0.0\n",
      "centers:  [[64 53  4]\n",
      " [64 53  5]\n",
      " [65 52  4]\n",
      " [65 53  4]\n",
      " [65 53  5]]\n",
      "centers.shape:  (5, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.99996448]\n",
      "frame_id: 30\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  0.133928 -286.746\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.556321 0.0\n",
      "centers:  []\n",
      "centers.shape:  (0, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.55632126]\n",
      "frame_id: 34\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  -0.240484 -209.644\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.37365 0.0\n",
      "centers:  []\n",
      "centers.shape:  (0, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.37364998]\n",
      "frame_id: 116\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  4.87238 -343.568\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.999937 0.0\n",
      "centers:  [[72 53  4]\n",
      " [73 53  4]\n",
      " [73 53  5]\n",
      " [73 54  4]\n",
      " [84 45  4]\n",
      " [84 45  5]\n",
      " [85 44  4]\n",
      " [85 44  5]\n",
      " [85 45  4]\n",
      " [85 45  5]\n",
      " [86 45  4]\n",
      " [94 14  6]]\n",
      "centers.shape:  (12, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.9999367]\n",
      "frame_id: 118\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n",
      "objectness.shape:  (100, 100, 10)\n",
      "objectness.max && min:  3.78144 -368.544\n",
      "y_pred.shape:  (100, 100, 10)\n",
      "y_pred.max && min:  0.999437 0.0\n",
      "centers:  [[71 53  4]\n",
      " [72 53  4]\n",
      " [84 44  5]\n",
      " [84 45  4]\n",
      " [84 45  5]\n",
      " [93 44  4]]\n",
      "centers.shape:  (6, 3)\n",
      "voxels_shape:  (?, 800, 800, 80, 1)\n",
      "confidence: [ 0.99943691]\n",
      "frame_id: 126\n",
      "INFO:tensorflow:Restoring parameters from /home/paperspace/Desktop/didi_solution/cnn_3d/3dcnn_800x800x80_res0.1_sc86.ckpt\n"
     ]
    }
   ],
   "source": [
    "results = defaultdict(make_frame_result_dict_shell)\n",
    "\n",
    "def get_orientation(corners_initial):\n",
    "    corners_initial = np.reshape(corners_initial, (-1, 3))\n",
    "    average = np.sum(corners_initial, axis=0) / corners_initial.shape[0]\n",
    "    corners = corners_initial - average\n",
    "    #print(corners[:, :2])\n",
    "    convx_hull = np.reshape(cv2.convexHull(np.array(corners[:, :2], dtype=np.float32)), (-1, 2))\n",
    "    rotated_convx_hull = np.vstack((convx_hull[1:], convx_hull[:1]))\n",
    "    distance_delta = convx_hull - rotated_convx_hull\n",
    "    distance_delta = np.linalg.norm(convx_hull - rotated_convx_hull, axis=1)\n",
    "    length_of_car_from_convex_hull = np.max(distance_delta)\n",
    "    width_of_car_from_convex_hull = np.min(distance_delta)\n",
    "    #print ('length of car:', length_of_car_from_convex_hull, 'width of car:', width_of_car_from_convex_hull)\n",
    "    l, w = length_of_car_from_convex_hull, width_of_car_from_convex_hull\n",
    "    a_mat = [[-l / 2., -w / 2.],\n",
    "            [l / 2., -w / 2.],\n",
    "            [-l / 2., w / 2.],\n",
    "            [-l / 2., -w / 2.],\n",
    "            [-l / 2., w / 2.],\n",
    "            [l / 2., w / 2.],\n",
    "            [l / 2., -w / 2.],\n",
    "            [l / 2., w / 2.]]\n",
    "    b_mat = corners[:, :2]\n",
    "    #pv(corners)\n",
    "    #pv(a_mat)\n",
    "    #pv(b_mat)\n",
    "    rot_mat = np.linalg.lstsq(a_mat, b_mat)[0]\n",
    "    angle = math.acos(rot_mat[0][0])\n",
    "    h = np.max(corners_initial[:, 2]) - np.min(corners_initial[:, 2])\n",
    "    return angle, l, w, h\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "model_name = \"3dcnn_800x800x80_res0.1_sc86.ckpt\"\n",
    "model_path = \"/home/paperspace/Desktop/didi_solution/cnn_3d/\"+model_name\n",
    "\n",
    "\n",
    "path_prefix = \"/home/paperspace/Desktop/converted/car/testing/ford01\"\n",
    "#path_prefix = \"/home/paperspace/Desktop/converted/car/training/nissan_driving_past_it/*/\"\n",
    "points_glob = path_prefix+\"/points/*.pcd\"\n",
    "\n",
    "\n",
    "i = 0\n",
    "for points_path in glob.glob(points_glob):\n",
    "    #if i == 10:\n",
    "    #    break\n",
    "    #i+=1\n",
    "        \n",
    "    frame_id = points_path.split('/')[-1].split('.')[0]\n",
    "    pv(frame_id)\n",
    "\n",
    "    coord, objectness, centers, y_pred, confidence = model_01_conv.test(model_path, points_path,\n",
    "                      voxel_shape=(800, 800, 80),\n",
    "                      resolution=0.1,\n",
    "                      scale=8, \n",
    "                      x=(-40, 40),\n",
    "                      y=(-40, 40),\n",
    "                      z=(-4, 4),\n",
    "                      min_certainty=0.95\n",
    "                     )\n",
    "\n",
    "    index = np.where(y_pred >= np.max(y_pred)) #0.99)#np.max(y_pred))\n",
    "    index = np.array(index)\n",
    "\n",
    "    centers = np.vstack((index[0], np.vstack((index[1], index[2])))).transpose()\n",
    "    centers = input_helpers.sphere2center(centers,\n",
    "                                    resolution=resolution,\n",
    "                                    scale=scale,\n",
    "                                    min_value=np.array([x[0], y[0], z[0]]))\n",
    "    #pv(centers.shape)\n",
    "    \n",
    "    corners = coord[index[0], index[1], index[2]].reshape(-1, 8, 3)\n",
    "    corners = np.array([corners[t,:,:] + centers[t,:] for t in range(corners.shape[0])])\n",
    "    \n",
    "    corners = bring_bbox_to_ground(corners)\n",
    "    #pv(corners.shape)\n",
    "    \n",
    "    confidence = y_pred[index[0], index[1], index[2]]\n",
    "    pv(confidence)\n",
    "    \n",
    "    rot = None\n",
    "    if centers.shape[0] == 0:\n",
    "        centers = None\n",
    "        corners = None\n",
    "        confidence = None\n",
    "    else:\n",
    "        rot = [get_orientation(corner) for corner in corners]\n",
    "    \n",
    "    \n",
    "    results[frame_id]['pred'] = {\n",
    "        'corners': corners,\n",
    "        'centers': centers,\n",
    "        'confidence': confidence,\n",
    "        'rot': rot\n",
    "    }\n",
    "    #pv(rot)\n",
    "    \n",
    "    #label_path = input_helpers.get_label_path_for_point_path(points_path)\n",
    "    #places, rots, size = input_helpers.read_labels(label_path)\n",
    "    #bbox = input_helpers.get_boxcorners(places, rots, size)\n",
    "    #results[frame_id]['actual'] = {\n",
    "    #    'corners': bbox,\n",
    "    #    'centers': places,\n",
    "    #    'size': size,\n",
    "    #    'rots': rots,\n",
    "    #}\n",
    "    \n",
    "    #pc = input_helpers.load_pc_from_pcd(points_path)\n",
    "    #if centers is not None:\n",
    "    #    publish_pc2(pc, centers.reshape(-1, 3))#, centers[:].reshape(-1, 3))\n",
    "    #else:\n",
    "    #    publish_pc2(pc, np.array([[0,0,0]]))\n",
    "    #break\n",
    "    \n",
    "pickle.dump( results, open(\"results_ford01.pickle\", \"wb\") )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv(coord.shape)\n",
    "pv(centers.shape)\n",
    "\n",
    "pv(y_pred.shape)\n",
    "pv(objectness.shape)\n",
    "print(\"-\")\n",
    "\n",
    "#label_path = input_helpers.get_label_path_for_point_path(points_path) \n",
    "pc = input_helpers.load_pc_from_pcd(points_path)\n",
    "pv(pc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cmin: \", np.min(coord) )\n",
    "print(\"cmax: \", np.max(coord) )\n",
    "\n",
    "print(\"omin: \", np.min(objectness) )\n",
    "print(\"omax: \", np.max(objectness) )\n",
    "\n",
    "print(\"ymin: \", np.min(y_pred) )\n",
    "print(\"ymax: \", np.max(y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.where(y_pred >= .95) \n",
    "index = np.array(index)\n",
    "pv(index.shape)\n",
    "\n",
    "centers = np.vstack((index[0], np.vstack((index[1], index[2])))).transpose()\n",
    "\n",
    "centers = input_helpers.sphere2center(centers,\n",
    "                                resolution=resolution,\n",
    "                                scale=scale,\n",
    "                                min_value=np.array([x[0], y[0], z[0]]))\n",
    "\n",
    "pv(centers.shape)\n",
    "#print(coord[0][16][85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv(index.shape)\n",
    "pv(coord.shape)\n",
    "pv(index[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = coord[index[0], index[1], index[2]][:, :3].reshape(-1, 3) + centers[:] #[:, np.newaxis] + centers\n",
    "pv(corners.shape)\n",
    "pv(corners)\n",
    "#pv(centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pc = input_helpers.load_pc_from_pcd(points_path)\n",
    "\n",
    "logic_x = np.logical_and(pc[:, 0] >= -60, pc[:, 0] < 60)\n",
    "logic_y = np.logical_and(pc[:, 1] >= -60, pc[:, 1] < 60)\n",
    "logic_z = np.logical_and(pc[:, 2] >= z[0], pc[:, 2] < z[1])\n",
    "\n",
    "pc_cropped = pc[:, :3][np.logical_and(logic_x, np.logical_and(logic_y, logic_z))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv(pc.shape)\n",
    "places, rots, size = input_helpers.read_labels(label_path)\n",
    "bbox = input_helpers.get_boxcorners(places, rots, size)\n",
    "pv(bbox.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv(corners.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_pc2(pc_cropped, corners.reshape(-1, 3), bbox.reshape(-1, 3))#, bbox.reshape(-1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(centers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cn = corners.reshape(-1, 3)\n",
    "pv(cn.shape)\n",
    "cn_zmin = np.array([0.0, 0.0, np.max(cn[:, 2])])\n",
    "pv(cn_zmin)\n",
    "#cn - \n",
    "crz = cn - cn_zmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_pcd = [102, 142, 186, 224, 265, 308, 349, 390, 42, 70, 104, 145, 188, 227, 267, 30, 34, 392, 431, 73, 106, 147, 18, 229, 270, 311, 351, 395, 433, 75, 109, 150, 191, 22, 272, 313, 354, 397, 436, 78, 10, 152, 193, 231, 275, 315, 356, 399, 438, 80, 111, 154, 195, 234, 277, 318, 359, 39, 440, 82, 114, 157, 198, 236, 279, 320, 361, 3, 443, 85, 116, 159, 1, 239, 27, 323, 363, 402, 44, 87, 118, 15, 200, 241, 282, 325, 366, 404, 46, 8, 121, 162, 203, 243, 284, 327, 368, 407, 49, 90, 123, 164, 205, 246, 287, 32, 371, 409, 51, 92, 126, 167, 207, 248, 289, 330, 373, 412, 54, 94, 128, 169, 20, 251, 291, 332, 375, 414, 56, 97, 130, 171, 210, 253, 294, 335, 378, 416, 58, 99, 133, 174, 212, 255, 296, 337, 37, 419, 61, 135, 176, 215, 258, 299, 339, 380, 421, 63, 138, 179, 217, 25, 301, 342, 383, 424, 66, 13, 181, 219, 260, 303, 344, 385, 426, 68, 140, 183, 222, 263, 306, 347, 387, 428, 6]\n",
    "labels = pt.parse_xml(\"/home/paperspace/Desktop/converted/car/training/nissan_driving_past_it/nissan07/tracklet_labels.xml\")\n",
    "print(len(existing_pcd))\n",
    "print(len(results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = objectness[0, :, :, :, 0][index].reshape(-1, 3)[:, np.newaxis] + centers\n",
    "#corners2 = objectness[0, :, :, :, 1][index].reshape(-1, 3)[:, np.newaxis] + centers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv(corners.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_pc2(pc,  corners.reshape(-1, 8, 3).reshape(-1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rospy\n",
    "node = rospy.init_node(\"pc2_publisher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sensor_msgs.msg import PointCloud2\n",
    "pub = rospy.Publisher(\"/points_raw\", PointCloud2, queue_size=1000000)\n",
    "pub2 = rospy.Publisher(\"/points_raw1\", PointCloud2, queue_size=1000000)\n",
    "pub3 = rospy.Publisher(\"/points_raw2\", PointCloud2, queue_size=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sensor_msgs.point_cloud2 as pc2\n",
    "\n",
    "def create_cloud_xyzi32(header, points):\n",
    "    fields = [pc2.PointField('x', 0, pc2.PointField.FLOAT32, 1),\n",
    "              pc2.PointField('y', 4, pc2.PointField.FLOAT32, 1),\n",
    "              pc2.PointField('z', 8, pc2.PointField.FLOAT32, 1),\n",
    "              pc2.PointField('intensity', 12, pc2.PointField.FLOAT32, 1)]\n",
    "    return pc2.create_cloud(header, fields, points)\n",
    "\n",
    "def publish_pc2(pcloud, obj=None, obj2=None):\n",
    "    \"\"\"Publisher of PointCloud data\"\"\"\n",
    "    import rospy\n",
    "    from sensor_msgs.msg import PointCloud2\n",
    "    import std_msgs\n",
    "    from visualization_msgs.msg import Marker\n",
    "    from geometry_msgs.msg import Point, TransformStamped\n",
    "\n",
    "    r = rospy.Rate(0.1)\n",
    "    \n",
    "    ts = rospy.Time.now()\n",
    "    \n",
    "    header = std_msgs.msg.Header()\n",
    "    header.stamp = ts\n",
    "    header.frame_id = \"velodyne\"\n",
    "    points = pc2.create_cloud_xyz32(header, pcloud)\n",
    "    pub.publish(points)\n",
    "\n",
    "    if obj is not None:\n",
    "        header = std_msgs.msg.Header()\n",
    "        header.stamp = ts\n",
    "        header.frame_id = \"velodyne\"\n",
    "        if obj.shape[-1] == 4:\n",
    "            points2 = create_cloud_xyzi32(header, obj)\n",
    "        else: \n",
    "            points2 = pc2.create_cloud_xyz32(header, obj)\n",
    "        pub2.publish(points2)\n",
    "        \n",
    "\n",
    "    if obj2 is not None:\n",
    "        header = std_msgs.msg.Header()\n",
    "        header.stamp = ts\n",
    "        header.frame_id = \"velodyne\"\n",
    "        points3 = pc2.create_cloud_xyz32(header, obj2)\n",
    "        pub3.publish(points3)\n",
    "\n",
    "    #while not rospy.is_shutdown():\n",
    "\n",
    "        \n",
    "    #if obj is not None:\n",
    "    #r.sleep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.utils.shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "points_glob = \"/home/paperspace/Desktop/converted/car/training/*/*/points/*.pcd\"\n",
    "labels_glob = \"/home/paperspace/Desktop/converted/car/training/*/*/labels/*.pickle\"\n",
    "\n",
    "def get_label_path_for_point_path(point_path):\n",
    "    ppath_parts = point_path.split('/')\n",
    "    ppath_parts[-1] = ppath_parts[-1].replace('pcd', 'pickle')\n",
    "    ppath_parts[-2] = 'labels'\n",
    "    return os.path.join(\"/\", *ppath_parts)\n",
    "  \n",
    "def visualize_points(points_path):#, label_path):\n",
    "    label_path = get_label_path_for_point_path(points_path)\n",
    "    pc = input_helpers.load_pc_from_pcd(points_path)\n",
    "    places, rots, size = input_helpers.read_labels(label_path)\n",
    "\n",
    "    #if(np.square(places[0]))\n",
    "    place_dist = np.sqrt(np.sum(np.square(places[0])))\n",
    "\n",
    "    if places is None or len(places.shape) == 0:\n",
    "        print(\"places is none for: %s, %s\" % (label_path, points_path))\n",
    "        #continue\n",
    "        return\n",
    "    \n",
    "    if place_dist > 50:\n",
    "        print(\"places is too far away (%s) for: %s, %s\"%(place_dist, label_path, points_path))\n",
    "        #return\n",
    "        #continue\n",
    "    else: \n",
    "        print(points_path, place_dist)\n",
    "        return True\n",
    "    \n",
    "    return None\n",
    "        \n",
    "    #corners = input_helpers.get_boxcorners(places, rots, size)\n",
    "    #publish_pc2(pc, corners.reshape(-1, 3))\n",
    "    #r.sleep()\n",
    "    #break\n",
    "\n",
    "\n",
    "points_paths = sorted( glob.glob(points_glob) )\n",
    "\n",
    "labels_paths = sorted( glob.glob(labels_glob) )\n",
    "\n",
    "#print(points_paths[0])\n",
    "#print(labels_paths)\n",
    "\n",
    "#visualize_points(points_paths[20])#, labels_paths[20])\n",
    "\n",
    "#points_path = points_paths[20]\n",
    "#pc = pcl.load(points_path)\n",
    "\n",
    "#z = np.array(pc.to_list())\n",
    "#z = np.array([[0, 0, 0]])\n",
    "r = rospy.Rate(0.5)\n",
    "for points_path in points_paths:\n",
    "    if visualize_points(points_path):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_paths[-1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.is_shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pc2voxel(pc, resolution=0.50, x=(0, 90), y=(-50, 50), z=(-4.5, 5.5), car_x=(-2, 2), car_y=(-2, 2), car_z=(-3, 2)):\n",
    "    \"\"\"Convert PointCloud2 to Voxel\"\"\"\n",
    "\n",
    "    # Filter out or own car :-()\n",
    "    car_logic_x = np.logical_and(pc[:, 0] > car_x[0], pc[:, 0] < car_x[1])\n",
    "    car_logic_y = np.logical_and(pc[:, 1] > car_y[0], pc[:, 1] < car_y[1])\n",
    "    car_logic_z = np.logical_and(pc[:, 2] > car_z[0], pc[:, 2] < car_z[1])\n",
    "    car_filter_xyz = np.logical_and(car_logic_x, np.logical_and(car_logic_y, car_logic_z))\n",
    "\n",
    "    logic_x = np.logical_and(pc[:, 0] >= x[0], pc[:, 0] < x[1])\n",
    "    logic_y = np.logical_and(pc[:, 1] >= y[0], pc[:, 1] < y[1])\n",
    "    logic_z = np.logical_and(pc[:, 2] >= z[0], pc[:, 2] < z[1])\n",
    "    logic_xyz = np.logical_and(logic_x, np.logical_and(logic_y, logic_z))\n",
    "\n",
    "    pc = pc[:, :3][np.logical_and(np.logical_not(car_filter_xyz), logic_xyz)]\n",
    "    pc = ((pc - np.array([x[0], y[0], z[0]])) / resolution).astype(np.int32)\n",
    "\n",
    "    voxel = np.zeros((int((x[1] - x[0]) / resolution),\n",
    "                      int((y[1] - y[0]) / resolution),\n",
    "                      int(round((z[1] - z[0]) / resolution))\n",
    "                      ))\n",
    "    voxel[pc[:, 0], pc[:, 1], pc[:, 2]] = 1\n",
    "    return voxel\n",
    "\n",
    "def get_boxcorners(places, rots, size):\n",
    "    \"\"\"Create 8 corners of bounding box from bottom center.\"\"\"\n",
    "    corners = []\n",
    "    for place, rot, sz in zip(places, rots, size):\n",
    "        x, y, z = place\n",
    "        h, w, l = sz\n",
    "        if l > 10:\n",
    "            continue\n",
    "\n",
    "        corner = np.array([\n",
    "            [x - l / 2.0, y - w / 2.0, z],\n",
    "            [x + l / 2.0, y - w / 2.0, z],\n",
    "            [x - l / 2.0, y + w / 2.0, z],\n",
    "            [x - l / 2.0, y - w / 2.0, z + h],\n",
    "            [x - l / 2.0, y + w / 2.0, z + h],\n",
    "            [x + l / 2.0, y + w / 2.0, z],\n",
    "            [x + l / 2.0, y - w / 2.0, z + h],\n",
    "            [x + l / 2.0, y + w / 2.0, z + h],\n",
    "        ])\n",
    "\n",
    "        corner -= np.array([x, y, z])\n",
    "\n",
    "        rot_matrix = np.array([\n",
    "            [np.cos(rot), -np.sin(rot), 0],\n",
    "            [np.sin(rot), np.cos(rot), 0],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "\n",
    "        a = np.dot(corner, rot_matrix.transpose())\n",
    "        a += np.array([x, y, z])\n",
    "        corners.append(a)\n",
    "    return np.array(corners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_label(places, size, corners, resolution=0.50, x=(0, 90), y=(-50, 50), z=(-4.5, 5.5), scale=4, min_value=None):\n",
    "    \"\"\"Create training Labels\"\"\"\n",
    "\n",
    "    if min_value is None:\n",
    "        #min_value = [0.0, 0.0, 0.0]\n",
    "        min_value = [x[0], y[0], z[0]]\n",
    "    min_value = np.array(min_value)\n",
    "\n",
    "    places = np.array(places)\n",
    "    size = np.array(size)\n",
    "    corners = np.array(corners)\n",
    "\n",
    "    x_logical = np.logical_and((places[:, 0] < x[1]), (places[:, 0] >= x[0]))\n",
    "    y_logical = np.logical_and((places[:, 1] < y[1]), (places[:, 1] >= y[0]))\n",
    "    z_logical = np.logical_and((places[:, 2] + size[:, 0] / 2.0 < z[1]), (places[:, 2] + size[:, 0] / 2.0 >= z[0]))\n",
    "    xyz_logical = np.logical_and(x_logical, np.logical_and(y_logical, z_logical))\n",
    "\n",
    "    center = places.copy()\n",
    "    #center[:, 2] = center[:, 2] + size[:, 0] / 2.0  # Move bottom to center\n",
    "    sphere_center = ((center[xyz_logical] - min_value) / (resolution * scale)).astype(np.int32)\n",
    "\n",
    "    train_corners = corners[xyz_logical].copy()\n",
    "    anchor_center = sphere2center(sphere_center,\n",
    "                                     resolution=resolution,\n",
    "                                     scale=scale,\n",
    "                                     min_value=min_value)\n",
    "\n",
    "    #for index, (corner, center) in enumerate(zip(corners[xyz_logical], anchor_center)):\n",
    "    #    train_corners[index] = corner - center\n",
    "\n",
    "    return sphere_center, train_corners\n",
    "\n",
    "\n",
    "def sphere2center(p_sphere, resolution=0.5, scale=4, min_value=None):\n",
    "    \"\"\"from sphere center to label center\"\"\"\n",
    "\n",
    "    if min_value is None:\n",
    "        min_value = [0.0, 0.0, 0.0]\n",
    "    min_value = np.array(min_value)\n",
    "\n",
    "    center = p_sphere * (resolution * scale) + min_value\n",
    "    return center\n",
    "\n",
    "def corner_to_train(corners, sphere_center, resolution=0.50, x=(0, 90), y=(-50, 50), z=(-4.5, 5.5), scale=4, min_value=None):\n",
    "    \"\"\"Convert corner to Training label for regression loss\"\"\"\n",
    "\n",
    "    if min_value is None:\n",
    "        #min_value = [0.0, 0.0, 0.0]\n",
    "        min_value = [x[0], y[0], z[0]]\n",
    "    min_value = np.array(min_value)\n",
    "\n",
    "    x_logical = np.logical_and((corners[:, :, 0] < x[1]), (corners[:, :, 0] >= x[0]))\n",
    "    y_logical = np.logical_and((corners[:, :, 1] < y[1]), (corners[:, :, 1] >= y[0]))\n",
    "    z_logical = np.logical_and((corners[:, :, 2] < z[1]), (corners[:, :, 2] >= z[0]))\n",
    "    xyz_logical = np.logical_and(x_logical, np.logical_and(y_logical, z_logical)).all(axis=1)\n",
    "\n",
    "    train_corners = corners[xyz_logical].copy()\n",
    "    sphere_center = sphere2center(sphere_center,\n",
    "                                     resolution=resolution,\n",
    "                                     scale=scale,\n",
    "                                     min_value=min_value)\n",
    "\n",
    "    #for index, (corner, center) in enumerate(zip(corners[xyz_logical], sphere_center)):\n",
    "        #train_corners[index] = corner - center\n",
    "\n",
    "    return train_corners\n",
    "\n",
    "\n",
    "def corner_to_voxel(voxel_shape, corners, sphere_center, scale=4):\n",
    "    \"\"\"Create final regression label from corner\"\"\"\n",
    "    # import pdb\n",
    "    # pdb.set_trace()\n",
    "    corner_voxel = np.zeros((int(voxel_shape[0] / scale),\n",
    "                             int(voxel_shape[1] / scale),\n",
    "                             int(voxel_shape[2] / scale), 24))\n",
    "    corner_voxel[sphere_center[:, 0], sphere_center[:, 1], sphere_center[:, 2]] = corners\n",
    "    return corner_voxel\n",
    "\n",
    "def create_objectness_label(sphere_center, resolution=0.5, x=90, y=100, z=10, scale=4):\n",
    "    \"\"\"Create Objectness label\"\"\"\n",
    "    obj_maps = np.zeros((int(x / (resolution * scale)),\n",
    "                         int(y / (resolution * scale)),\n",
    "                         int(np.round(z / (resolution * scale)))\n",
    "                         ))\n",
    "    obj_maps[sphere_center[:, 0], sphere_center[:, 1], sphere_center[:, 2]] = 1\n",
    "    return obj_maps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points_path = \"/home/paperspace/Desktop/converted/car/training/bmw_sitting_still/bmw01/points/1.pcd\"\n",
    "label_path = get_label_path_for_point_path(points_path) \n",
    "pc = input_helpers.load_pc_from_pcd(points_path)\n",
    "places, rots, size = input_helpers.read_labels(label_path)\n",
    "points = pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voxel_shape=(600, 600, 40)\n",
    "resolution=0.2\n",
    "scale=1\n",
    "x=(-60, 60)\n",
    "y=(-60, 60)\n",
    "z=(-4, 4)\n",
    "car_x=(-2, 2)\n",
    "car_y=(-2, 2)\n",
    "car_z=(-3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"%sx%sx%s_\"%voxel_shape)+(\"res%s_\" % resolution)+(\"sc%s\"%scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = get_boxcorners(places, rots, size)\n",
    "print(\"corners: \", corners.shape, corners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "center_sphere, corner_label = create_label(places, size, corners,\n",
    "                                           resolution=resolution,\n",
    "                                           x=x,\n",
    "                                           y=y,\n",
    "                                           z=z,\n",
    "                                           scale=scale,\n",
    "                                           min_value=[x[0], y[0], z[0]])\n",
    "\n",
    "print(\"center_sphere: \", center_sphere)\n",
    "print(\"corner_label: \", corner_label.shape, corner_label)\n",
    "\n",
    "g_map = create_objectness_label(center_sphere,\n",
    "                                            resolution=resolution,\n",
    "                                            x=(x[1] - x[0]),\n",
    "                                            y=(y[1] - y[0]),\n",
    "                                            z=(z[1] - z[0]),\n",
    "                                            scale=scale)\n",
    "\n",
    "print('g_map: ', np.argwhere(g_map > 0))\n",
    "\n",
    "g_cord = corner_label.reshape(corner_label.shape[0], -1)\n",
    "print(g_cord.shape)\n",
    "g_cord = corner_to_voxel(voxel_shape, g_cord, center_sphere, scale=scale)\n",
    "print(g_cord.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc = np.argwhere(g_cord > 0)\n",
    "gm = np.argwhere(g_map > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_01_conv.layers.cnn_model.layer2.get_shape().as_list()\n",
    "\n",
    "print(gm.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gc.shape)\n",
    "print(gm.shape)\n",
    "print(gm)\n",
    "print(center_sphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nice_voxel(voxel):\n",
    "    v = voxel\n",
    "\n",
    "    v[:, 0] = v[:, 0] - np.min(v[:, 0])\n",
    "    v[:, 1] = v[:, 1] - np.min(v[:, 1])\n",
    "    v[:, 2] = v[:, 2] - np.min(v[:, 2])\n",
    "\n",
    "    v[:, 0] = v[:, 0] - np.mean(v[:, 0])\n",
    "    v[:, 1] = v[:, 1] - np.mean(v[:, 1])\n",
    "    v[:, 2] = v[:, 2] - np.mean(v[:, 2])\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Publisher of PointCloud data\"\"\"\n",
    "import rospy\n",
    "import sensor_msgs.point_cloud2 as pc2\n",
    "from sensor_msgs.msg import PointCloud2\n",
    "import std_msgs\n",
    "from visualization_msgs.msg import Marker\n",
    "from geometry_msgs.msg import Point, TransformStamped\n",
    "from sensor_msgs.msg import PointCloud2\n",
    "\n",
    "#voxel[:, 0] = np.mean(voxel[:, 0])\n",
    "\n",
    "#publish_pc2(v)\n",
    "\n",
    "\n",
    "v = np.argwhere(pc2voxel(pc, x=x, y=y, z=z, resolution=resolution)>0)\n",
    "corn = np.argwhere(pc2voxel(corners[0], x=x, y=y, z=z, resolution=resolution))\n",
    "\n",
    "v=nice_voxel(v)\n",
    "corn=nice_voxel(corn)\n",
    "\n",
    "\n",
    "r = rospy.Rate(0.5)\n",
    "for _ in range(2):\n",
    "    header = std_msgs.msg.Header()\n",
    "    header.stamp = rospy.Time.now()\n",
    "    header.frame_id = \"velodyne\"\n",
    "    points = pc2.create_cloud_xyz32(header, v)\n",
    "    pub3.publish(points)\n",
    "    \n",
    "    header = std_msgs.msg.Header()\n",
    "    header.stamp = rospy.Time.now()\n",
    "    header.frame_id = \"velodyne\"\n",
    "    points = pc2.create_cloud_xyz32(header, corn)\n",
    "    pub2.publish(points)\n",
    "    \n",
    "    \n",
    "    #r.sleep()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
